# Streaming output setting (True or False)
STREAMING_OUTPUT="True"
# key Hugging_hub = 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
PINECONE_API_KEY = '9545d46d-b610-4715-bd26-a24282160287'
# Log level setting (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL="INFO"

#-------------------------------------
# Cache directory for models
CACHE_DIR="./cache"

#-------------------------------------
# Vector store settings
REGENERATE_VECTORSTORE="True"

#-------------------------------------
# Text embeddings model 
# (default model for langchain.embeddings.HuggingFaceEmbeddings is all-mpnet-base-v2)
MODEL_EMBEDDINGS="sentence-transformers/all-mpnet-base-v2"
#MODEL_EMBEDDINGS="jinaai/jina-embeddings-v2-base-en"

#-------------------------------------
# LLM Model settings
MODEL_VENDOR="meta-llama"
MODEL_NAME="Meta-Llama-3-8B"

# MODEL_VENDOR="TinyLlama"
# MODEL_NAME="TinyLlama-1.1B-Chat-v0.6"

# MODEL_VENDOR="HuggingFaceH4"
# MODEL_NAME="zephyr-7b-beta"

# MODEL_VENDOR="Intel"
# MODEL_NAME="neural-chat-7b-v3-1"

# MODEL_VENDOR="databricks"
# MODEL_NAME="dolly-v2-3b"

# MODEL_VENDOR="rinna"
# MODEL_NAME="youri-7b-chat"

#-------------------------------------
# OpenVINO Settings
MODEL_PRECISION="FP16"          # "FP16", "INT8", "INT4"
INFERENCE_DEVICE="CPU"          # "CPU", "GPU", "GPU.0" (iGPU), "GPU.1" (dGPU)
SOURCE_DOCUMENT = "./dpcpp_all.pdf"
STREAMING_OUTPUT = True      # True or False

#-------------------------------------
# Cache for models
CACHE_DIR="./cache"

#-------------------------------------
# Vector store settings
VECTORSTORE_PATH="./vectorstore"
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
#-------------------------------------
# Text embeddings model 
# (the default model for langchain.embeddings.HuggingFaceEmbeddings is all-mpnet-base-v2)
MODEL_EMBEDDINGS = "sentence-transformers/all-mpnet-base-v2"
#MODEL_EMBEDDINGS = "jinaai/jina-embeddings-v2-base-en"

#-------------------------------------
# LLM Model settings
#MODEL_VENDOR="meta-llama"
#MODEL_NAME="Llama-2-7b-chat-hf"

MODEL_VENDOR="TinyLlama"
MODEL_NAME="TinyLlama-1.1B-Chat-v0.6"

#MODEL_VENDOR="HuggingFaceH4"
#MODEL_NAME="zephyr-7b-beta"

#MODEL_VENDOR="Intel"
#MODEL_NAME="neural-chat-7b-v3-1"

#MODEL_VENDOR="databricks"
#MODEL_NAME="dolly-v2-3b"

#-------------------------------------
# OpenVINO Settings
MODEL_PRECISION="INT4"          # "FP16", "INT8", "INT4"
INFERENCE_DEVICE="CPU"          # "CPU", "GPU", "GPU.0" (iGPU), "GPU.1" (dGPU)

#-------------------------------------
# RAG Generation/Pipeline settings
NUM_MAX_TOKENS=300
RAG_CHAIN_TYPE="stuff"      # "stuff", "map_reduce", "map_rerank", "refine"

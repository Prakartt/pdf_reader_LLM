
STREAMING_OUTPUT = True      # True or False
LOG_LEVEL = "INFO"           # DEBUG, INFO, WARNING, ERROR, CRITICAL

#-------------------------------------
# Cache for models
CACHE_DIR="./cache"

#-------------------------------------
# Vector store settings
REGENERATE_VECTORSTORE = True

#-------------------------------------
# Text embeddings model 
# (the default model for langchain.embeddings.HuggingFaceEmbeddings is all-mpnet-base-v2)
MODEL_EMBEDDINGS = "sentence-transformers/all-mpnet-base-v2"
#MODEL_EMBEDDINGS = "jinaai/jina-embeddings-v2-base-en"

#-------------------------------------
# LLM Model settings
#MODEL_VENDOR="meta-llama"
#MODEL_NAME="Llama-2-7b-chat-hf"

#MODEL_VENDOR="TinyLlama"
#MODEL_NAME="TinyLlama-1.1B-Chat-v0.6"

#MODEL_VENDOR="HuggingFaceH4"
#MODEL_NAME="zephyr-7b-beta"

#MODEL_VENDOR="Intel"
#MODEL_NAME="neural-chat-7b-v3-1"

#MODEL_VENDOR="databricks"
#MODEL_NAME="dolly-v2-3b"

MODEL_VENDOR="rinna"
MODEL_NAME="youri-7b-chat"

#-------------------------------------
# OpenVINO Settings
MODEL_PRECISION="INT4"          # "FP16", "INT8", "INT4"
INFERENCE_DEVICE="CPU"          # "CPU", "GPU", "GPU.0" (iGPU), "GPU.1" (dGPU)
